{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/river/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "from keras_helper import NNWeightHelper\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from snes import SNES\n",
    "from numpy import argmax\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 28, 28\n",
    "train_data_dir = \"/home/river/assi2_ce888/Offical31_datasets/amazon/images\"\n",
    "\n",
    "validation_data_dir = \"/home/river/assi2_ce888/Offical31_datasets/dslr/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nb_train_samples = 527\n",
    "#nb_validation_samples = 423\n",
    "epochs = 30\n",
    "batch_size = 160\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(31))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss = \"mean_squared_error\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2817 images belonging to 31 classes.\n",
      "Found 498 images belonging to 31 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    #save_to_dir= \"/home/river/assi2_ce888/Offical31_datasets/save_pic1\",\n",
    "    target_size=(img_width, img_height),\n",
    "    #color_mode = \"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    #color_mode =\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_test_ssamples = len(validation_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_imgs, train1_labels= next(train_generator)\n",
    "test_imgs, test1_labels =next(validation_generator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#shapes_labels=train_generator.class_indices\n",
    "#shapes_test= validation_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labells  =train_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.zeros((train1_labels.shape[0],), dtype = float)\n",
    "for i in range(train1_labels.shape[0]):\n",
    "    train_labels[i] = argmax(train1_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_labels = np.zeros((test1_labels.shape[0],), dtype = float)\n",
    "for i in range(test1_labels.shape[0]):\n",
    "    test_labels[i] = argmax(test1_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nb_train_samples = len(train_generator.filenames)\n",
    "#nb_validation_samples = len(validation_generator.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1_labels = to_categorical(test_labels, num_classes=num_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score ,acc= model.evaluate_generator(validation_generator, nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(score)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_f  = model.predict_generator(train_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SAMPLE_SIZE = 1024\n",
    "#SAMPLE_SIZE = int(math.ceil(nb_train_samples / batch_size))\n",
    "SAMPLE_SIZE = int(nb_train_samples / batch_size)\n",
    "# how many different sets of weights ask() should return for evaluation\n",
    "POPULATION_SIZE = 10\n",
    "# how many times we will loop over ask()/tell()\n",
    "GENERATIONS = 30\n",
    "\n",
    "def train_classifier(model, X,y):\n",
    "    #History= model.predict_generator(X, steps= 177)\n",
    "    #X_features = History.history\n",
    "    X_features = model.predict(X)\n",
    "    #clf = ExtraTreesClassifier(n_estimators=100, n_jobs=4)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    #clf = RandomForestClassifier(n_estimators=100, n_jobs=4)\n",
    "\n",
    "    clf.fit(X_features,y)\n",
    "    y_pred = clf.predict(X_features)\n",
    "    return clf, y_pred\n",
    "\n",
    "\n",
    "def predict_classifier(model, clf, X):\n",
    "    #X_features = model.predict_generator(X,steps = 177)\n",
    "    X_features = model.predict(X)\n",
    "    return clf.predict(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnw = NNWeightHelper(model)\n",
    "weights = nnw.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of weights to evolve is: (34815,)\n",
      "train_imgs shape is : (160, 28, 28, 3)\n",
      "train-labels shape is : (160,)\n",
      "(160,) (160,)\n",
      "Non-trained NN Test accuracy: 0.0375\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of weights to evolve is:\", weights.shape)\n",
    "\n",
    "all_examples_indices = list(range(train_imgs.shape[0]))\n",
    "clf, _ = train_classifier(model, train_imgs,train_labels)\n",
    "#clf, _ = train_classifier(model, train_imgs,train_labels)\n",
    "print(\"train_imgs shape is :\", train_imgs.shape)\n",
    "print(\"train-labels shape is :\",train_labels.shape)\n",
    "y_pred = predict_classifier(model, clf, test_imgs)\n",
    "\n",
    "#y_pred = predict_classifier(model, clf, test_imgs)\n",
    "\n",
    "print(test_labels.shape, y_pred.shape)\n",
    "test_accuracy = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "print('Non-trained NN Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snes  = SNES(weights, 1 , POPULATION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]\n"
     ]
    }
   ],
   "source": [
    "print(SAMPLE_SIZE)\n",
    "print(all_examples_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.18478077399959147 seconds to complete generation 1\n",
      "Step 2.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.22460470400073973 seconds to complete generation 2\n",
      "Step 3.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.2243277930010663 seconds to complete generation 3\n",
      "Step 4.0 : 0.1111111111111111 best: 0.16666666666666666 10\n",
      "It took 0.22499678900021536 seconds to complete generation 4\n",
      "Step 5.0 : 0.05555555555555555 best: 0.16666666666666666 10\n",
      "It took 0.2598590249999688 seconds to complete generation 5\n",
      "Step 6.0 : 0.0 best: 0.16666666666666666 10\n",
      "It took 0.22458732599989162 seconds to complete generation 6\n",
      "Step 7.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.22777171899906534 seconds to complete generation 7\n",
      "Step 8.0 : 0.05555555555555555 best: 0.16666666666666666 10\n",
      "It took 0.22715325399985886 seconds to complete generation 8\n",
      "Step 9.0 : 0.05555555555555555 best: 0.16666666666666666 10\n",
      "It took 0.22822532700047304 seconds to complete generation 9\n",
      "Step 10.0 : 0.05555555555555555 best: 0.16666666666666666 10\n",
      "It took 0.2228839510007674 seconds to complete generation 10\n",
      "Step 11.0 : 0.05555555555555555 best: 0.16666666666666666 10\n",
      "It took 0.24082179099968926 seconds to complete generation 11\n",
      "Step 12.0 : 0.1111111111111111 best: 0.16666666666666666 10\n",
      "It took 0.2253072620005696 seconds to complete generation 12\n",
      "Step 13.0 : 0.1111111111111111 best: 0.16666666666666666 10\n",
      "It took 0.22179183899970667 seconds to complete generation 13\n",
      "Step 14.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.22218336100013403 seconds to complete generation 14\n",
      "Step 15.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.22923783799888042 seconds to complete generation 15\n",
      "Step 16.0 : 0.1111111111111111 best: 0.16666666666666666 10\n",
      "It took 0.22828977600147482 seconds to complete generation 16\n",
      "Step 17.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.22886547300004167 seconds to complete generation 17\n",
      "Step 18.0 : 0.05555555555555555 best: 0.16666666666666666 10\n",
      "It took 0.2246214560000226 seconds to complete generation 18\n",
      "Step 19.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.21861527400142222 seconds to complete generation 19\n",
      "Step 20.0 : 0.1111111111111111 best: 0.16666666666666666 10\n",
      "It took 0.22560352900109137 seconds to complete generation 20\n",
      "Step 21.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.2216780930011737 seconds to complete generation 21\n",
      "Step 22.0 : 0.16666666666666666 best: 0.16666666666666666 10\n",
      "It took 0.2284097350002412 seconds to complete generation 22\n",
      "Step 23.0 : 0.2222222222222222 best: 0.2222222222222222 10\n",
      "It took 0.21850599000026705 seconds to complete generation 23\n",
      "Step 24.0 : 0.1111111111111111 best: 0.2222222222222222 10\n",
      "It took 0.22027429500121798 seconds to complete generation 24\n",
      "Step 25.0 : 0.16666666666666666 best: 0.2222222222222222 10\n",
      "It took 0.22821139699954074 seconds to complete generation 25\n",
      "Step 26.0 : 0.05555555555555555 best: 0.2222222222222222 10\n",
      "It took 0.2278729999998177 seconds to complete generation 26\n",
      "Step 27.0 : 0.1111111111111111 best: 0.2222222222222222 10\n",
      "It took 0.22893746599947917 seconds to complete generation 27\n",
      "Step 28.0 : 0.1111111111111111 best: 0.2222222222222222 10\n",
      "It took 0.22662960399975418 seconds to complete generation 28\n",
      "Step 29.0 : 0.05555555555555555 best: 0.2222222222222222 10\n",
      "It took 0.22150851799960947 seconds to complete generation 29\n",
      "Step 30.0 : 0.1111111111111111 best: 0.2222222222222222 10\n",
      "It took 0.2555352750005113 seconds to complete generation 30\n",
      "(160,) (160,)\n",
      "Test accuracy: 0.0375\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, GENERATIONS):\n",
    "    start = timer()\n",
    "    asked = snes.ask()\n",
    "    \n",
    "    told = []\n",
    "    subsample_indices  = np.random.choice(all_examples_indices, size= SAMPLE_SIZE,replace = False )\n",
    "    subsample_indices_valid = np.random.choice(all_examples_indices,size=SAMPLE_SIZE+1, replace = False)\n",
    "    for asked_j in asked:\n",
    "        nnw.set_weights(asked_j)\n",
    "        clf, _ = train_classifier(model, train_imgs[subsample_indices], train_labels[subsample_indices])\n",
    "        \n",
    "        y_pred = predict_classifier(model, clf, train_imgs[subsample_indices_valid])\n",
    "        score = accuracy_score(train_labels[subsample_indices_valid], y_pred)\n",
    "        \n",
    "        \n",
    "        # clf, _ = train_classifier(model, x_train, y_train)\n",
    "        # y_pred = predict_classifier(model, clf, x_test)\n",
    "        # score = accuracy_score(y_test, y_pred)\n",
    "        # append to array of values that are to be returned\n",
    "        told.append(score)\n",
    "        \n",
    "    snes.tell(asked, told)\n",
    "    end = timer()\n",
    "    print(\"It took\", end - start, \"seconds to complete generation\", i + 1)\n",
    "\n",
    "nnw.set_weights(snes.center)\n",
    "\n",
    "clf, _ = train_classifier(model, train_imgs, train_labels)\n",
    "y_pred = predict_classifier(model, clf, test_imgs)\n",
    "#print(told)\n",
    "\n",
    "print(test_labels.shape, y_pred.shape)\n",
    "test_accuracy = accuracy_score(test_labels, y_pred)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "    \n",
    "#cm  = confusion_matrix(y_test, y_pred)\n",
    "#plt.plot(told)\n",
    "#plt.title(\"loss model\")\n",
    "#plt.xlabel(\"genaration\")\n",
    "#plt.ylabel(\"loss_value\")\n",
    "#plt.legend(\"test\",loc = \"upper left\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
