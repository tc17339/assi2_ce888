{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/river/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from numpy import argmax\n",
    "from keras_helper import NNWeightHelper\n",
    "from snes import SNES\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 28, 28\n",
    "train_data_dir = \"/home/river/assi2_ce888/Offical31_datasets/amazon/images\"\n",
    "\n",
    "validation_data_dir = \"/home/river/assi2_ce888/Offical31_datasets/dslr/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_train_samples = 527\n",
    "nb_validation_samples = 423\n",
    "epochs = 30\n",
    "batch_size = 160\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2817 images belonging to 31 classes.\n",
      "Found 498 images belonging to 31 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    #save_to_dir= \"/home/river/assi2_ce888/Offical31_datasets/save_pic1\",\n",
    "    target_size=(img_width, img_height),\n",
    "    #color_mode = \"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    #color_mode =\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_imgs, train_labels= train_generator.next()\n",
    "#test_imgs, test_labels = validation_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = next(validation_generator)\n",
    "test_imgs = test_data[0]\n",
    "test_labels = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_imgs = train_data[0]\n",
    "train_labels = train_data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_labels = np.zeros((train1_labels.shape[0],), dtype = float)\n",
    "for i in range(train1_labels.shape[0]):\n",
    "    train_labels[i] = argmax(train1_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_labels = np.zeros((test1_labels.shape[0],), dtype = float)\n",
    "for i in range(test1_labels.shape[0]):\n",
    "    test_labels[i] = argmax(test1_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 31)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2817,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(31))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = \"mean_squared_error\",\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0312 - acc: 0.0375\n",
      "Epoch 2/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0313 - acc: 0.0188\n",
      "Epoch 3/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0500\n",
      "Epoch 4/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0250\n",
      "Epoch 5/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0375\n",
      "Epoch 6/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0437\n",
      "Epoch 7/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0500\n",
      "Epoch 8/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0688\n",
      "Epoch 9/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0500\n",
      "Epoch 10/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0500\n",
      "Epoch 11/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0250\n",
      "Epoch 12/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0437\n",
      "Epoch 13/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0375\n",
      "Epoch 14/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 0.0688\n",
      "Epoch 15/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0688\n",
      "Epoch 16/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0562\n",
      "Epoch 17/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0625\n",
      "Epoch 18/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0625\n",
      "Epoch 19/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0500\n",
      "Epoch 20/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0500\n",
      "Epoch 21/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0500\n",
      "Epoch 22/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0625\n",
      "Epoch 23/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0437\n",
      "Epoch 24/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0562\n",
      "Epoch 25/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0437\n",
      "Epoch 26/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0310 - acc: 0.0375\n",
      "Epoch 27/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0562\n",
      "Epoch 28/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0310 - acc: 0.0437\n",
      "Epoch 29/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0311 - acc: 0.0500\n",
      "Epoch 30/30\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0310 - acc: 0.0938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0f3f069fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_imgs, train_labels,\n",
    "          epochs=epochs,  \n",
    "          batch_size=batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 1024\n",
    "# how many different sets of weights ask() should return for evaluation\n",
    "POPULATION_SIZE = 10\n",
    "# how many times we will loop over ask()/tell()\n",
    "GENERATIONS = 30\n",
    "\n",
    "def train_classifier(model, X,y):\n",
    "    #History= model.predict_generator(X, steps= 177)\n",
    "    #X_features = History.history\n",
    "    X_features = model.predict(X)\n",
    "    #clf = ExtraTreesClassifier(n_estimators=100, n_jobs=4)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    #clf = RandomForestClassifier(n_estimators=100, n_jobs=4)\n",
    "\n",
    "    clf.fit(X_features,y)\n",
    "    y_pred = clf.predict(X_features)\n",
    "    return clf, y_pred\n",
    "\n",
    "\n",
    "def predict_classifier(model, clf, X):\n",
    "    #X_features = model.predict_generator(X,steps = 177)\n",
    "    X_features = model.predict(X)\n",
    "    return clf.predict(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnw = NNWeightHelper(model)\n",
    "weights = nnw.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of weights to evolve is: (34815,)\n",
      "train_imgs shape is : (160, 28, 28, 3)\n",
      "train-labels shape is : (160, 31)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(160, 31) (160, 31)\n",
      "Non-trained NN Test accuracy: 0.05625\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of weights to evolve is:\", weights.shape)\n",
    "\n",
    "all_examples_indices = list(range(train_imgs.shape[0]))\n",
    "clf, _ = train_classifier(model, train_imgs,train_labels)\n",
    "#clf, _ = train_classifier(model, train_imgs,train_labels)\n",
    "print(\"train_imgs shape is :\", train_imgs.shape)\n",
    "print(\"train-labels shape is :\",train_labels.shape)\n",
    "y_pred = predict_classifier(model, clf, test_imgs)\n",
    "print(y_pred)\n",
    "#y_pred = predict_classifier(model, clf, test_imgs)\n",
    "\n",
    "print(test_labels.shape, y_pred.shape)\n",
    "test_accuracy = accuracy_score(test_labels, y_pred)\n",
    "\n",
    "print('Non-trained NN Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snes  = SNES(weights, 1 , POPULATION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1.0 : 0.0 best: 0.0 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,) and (10,34815) not aligned: 1 (dim 0) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-59dd6719f91d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msnes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"It took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds to complete generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/river/assi2_ce888/tf-dann/snes.py\u001b[0m in \u001b[0;36mtell\u001b[0;34m(self, asked, fitnesses)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# update center and variances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mutilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeUtilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmas\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mcovGradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmas\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearningRate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcovGradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,) and (10,34815) not aligned: 1 (dim 0) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "for i in range(0, GENERATIONS):\n",
    "    start = timer()\n",
    "    asked = snes.ask()\n",
    "    \n",
    "    told = []\n",
    "    subsample_indices  = np.random.choice(all_examples_indices, size= 15,replace = False)\n",
    "    subsample_indices_valid = np.random.choice(all_examples_indices,size=15+1,replace = False)\n",
    "    for asked_j in asked:\n",
    "        nnw.set_weights(asked_j)\n",
    "        clf, _ = train_classifier(model, train_imgs[subsample_indices], train_labels[subsample_indices])\n",
    "        \n",
    "        y_pred = predict_classifier(model, clf, train_imgs[subsample_indices_valid])\n",
    "        score = accuracy_score(train_labels[subsample_indices_valid], y_pred)\n",
    "\n",
    "        # clf, _ = train_classifier(model, x_train, y_train)\n",
    "        # y_pred = predict_classifier(model, clf, x_test)\n",
    "        # score = accuracy_score(y_test, y_pred)\n",
    "        # append to array of values that are to be returned\n",
    "        told.append(score)\n",
    "\n",
    "        snes.tell(asked, told)\n",
    "        end = timer()\n",
    "        print(\"It took\", end - start, \"seconds to complete generation\", i + 1)\n",
    "\n",
    "nnw.set_weights(snes.center)\n",
    "\n",
    "clf, _ = train_classifier(model, train_imgs, train_labels)\n",
    "y_pred = predict_classifier(model, clf, test_imgs)\n",
    "#print(told)\n",
    "\n",
    "print(test_labels.shape, y_pred.shape)\n",
    "test_accuracy = accuracy_score(test_labels, y_pred)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
